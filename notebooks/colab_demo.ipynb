{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SplatNLP Colab Demo\n",
        "\n",
        "This notebook downloads pretrained artifacts from DigitalOcean Spaces and runs:\n",
        "\n",
        "- Token-space inference (multi-label set completion)\n",
        "- Constraint-aware beam search to produce a legal build\n",
        "- (Optional) Ultra + SAE hook introspection / steering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_URL = \"https://github.com/cesaregarza/SplatNLP.git\"\n",
        "REPO_DIR = Path(\"/content/SplatNLP\")\n",
        "\n",
        "if not REPO_DIR.exists():\n",
        "    subprocess.run(\n",
        "        [\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, str(REPO_DIR)],\n",
        "        check=True,\n",
        "    )\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "sys.path.insert(0, str(REPO_DIR / \"src\"))\n",
        "print(\"Repo ready:\", REPO_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip -q install requests tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download artifacts (Full model)\n",
        "\n",
        "This grabs `model.pth`, `model_params.json`, `vocab.json`, `weapon_vocab.json`, and `model_info.json`.\n",
        "\n",
        "If you want the Ultra + SAE demo later in this notebook, set `DOWNLOAD_ULTRA_SAE = True`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from splatnlp.utils.download_artifacts import (\n",
        "    CORE_ARTIFACTS,\n",
        "    ULTRA_ARTIFACTS,\n",
        "    ULTRA_SAE_ARTIFACTS,\n",
        "    download_artifacts,\n",
        ")\n",
        "\n",
        "BASE_URL = \"https://splat-nlp.nyc3.cdn.digitaloceanspaces.com\"\n",
        "DATASET_DIR = \"dataset_v2\"\n",
        "OUT_DIR = Path(\"saved_models\") / DATASET_DIR\n",
        "\n",
        "DOWNLOAD_ULTRA_SAE = False\n",
        "\n",
        "artifacts = list(CORE_ARTIFACTS)\n",
        "if DOWNLOAD_ULTRA_SAE:\n",
        "    artifacts += list(ULTRA_ARTIFACTS) + list(ULTRA_SAE_ARTIFACTS)\n",
        "\n",
        "download_artifacts(\n",
        "    base_url=BASE_URL,\n",
        "    dataset_dir=DATASET_DIR,\n",
        "    out_dir=OUT_DIR,\n",
        "    artifacts=artifacts,\n",
        "    force=False,\n",
        "    timeout_s=180,\n",
        "    quiet=False,\n",
        "    dry_run=False,\n",
        ")\n",
        "\n",
        "print(\"Downloaded to:\", OUT_DIR)\n",
        "for p in sorted(OUT_DIR.iterdir()):\n",
        "    print(\" -\", p.name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load model + run token-space inference\n",
        "\n",
        "This shows the top token predictions (not yet a legal build).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import torch\n",
        "\n",
        "from splatnlp.model.models import SetCompletionModel\n",
        "from splatnlp.serve.tokenize import tokenize_build\n",
        "from splatnlp.utils.constants import NULL, PAD\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "params = json.loads((OUT_DIR / \"model_params.json\").read_text())\n",
        "vocab = json.loads((OUT_DIR / \"vocab.json\").read_text())\n",
        "weapon_vocab = json.loads((OUT_DIR / \"weapon_vocab.json\").read_text())\n",
        "\n",
        "pad_token_id = params.get(\"pad_token_id\", vocab[PAD])\n",
        "inv_vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "model = SetCompletionModel(**params)\n",
        "model.load_state_dict(torch.load(OUT_DIR / \"model.pth\", map_location=\"cpu\"))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "weapon_id = \"weapon_id_8000\" if \"weapon_id_8000\" in weapon_vocab else next(iter(weapon_vocab))\n",
        "partial_build = {\n",
        "    \"ink_saver_main\": 6,\n",
        "    \"run_speed_up\": 12,\n",
        "    \"intensify_action\": 10,\n",
        "}\n",
        "\n",
        "tokens = tokenize_build(partial_build)\n",
        "print(\"weapon_id:\", weapon_id)\n",
        "print(\"input tokens:\", tokens)\n",
        "\n",
        "input_tokens = torch.tensor([[vocab[t] for t in tokens]], device=device)\n",
        "input_weapons = torch.tensor([[weapon_vocab[weapon_id]]], device=device)\n",
        "key_padding_mask = input_tokens == pad_token_id\n",
        "\n",
        "with torch.no_grad():\n",
        "    probs = torch.sigmoid(\n",
        "        model(input_tokens, input_weapons, key_padding_mask=key_padding_mask)\n",
        "    ).squeeze(0)\n",
        "\n",
        "probs_cpu = probs.detach().cpu()\n",
        "skip = {vocab.get(PAD), vocab.get(NULL)}\n",
        "top = torch.topk(probs_cpu, k=min(20, probs_cpu.numel()))\n",
        "for idx, p in zip(top.indices.tolist(), top.values.tolist()):\n",
        "    if idx in skip:\n",
        "        continue\n",
        "    print(f\"{inv_vocab[idx]:<32} {float(p):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Beam search: token-space → legal build-space\n",
        "\n",
        "This uses the repo’s constraint-aware reconstruction (allocator + beam search) to produce a legal build.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from splatnlp.utils.reconstruct.allocator import Allocator\n",
        "from splatnlp.utils.reconstruct.beam_search import reconstruct_build\n",
        "\n",
        "allocator = Allocator()\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "def predict_fn(current_tokens: list[str], weapon_id: str):\n",
        "    ids = [vocab[t] for t in current_tokens]\n",
        "    x = torch.tensor([ids], device=device)\n",
        "    w = torch.tensor([[weapon_vocab[weapon_id]]], device=device)\n",
        "    mask = x == pad_token_id\n",
        "    with torch.no_grad():\n",
        "        probs = torch.sigmoid(model(x, w, key_padding_mask=mask)).squeeze(0)\n",
        "    probs = probs.detach().cpu().tolist()\n",
        "    return {inv_vocab[i]: float(probs[i]) for i in range(vocab_size)}\n",
        "\n",
        "builds = reconstruct_build(\n",
        "    predict_fn=predict_fn,\n",
        "    weapon_id=weapon_id,\n",
        "    initial_context=[NULL],\n",
        "    allocator=allocator,\n",
        "    beam_size=5,\n",
        "    max_steps=6,\n",
        "    top_k=1,\n",
        ")\n",
        "\n",
        "if not builds:\n",
        "    raise RuntimeError(\"No valid build produced\")\n",
        "\n",
        "build = builds[0]\n",
        "build.to_dict()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Ultra + SAE hook demo\n",
        "\n",
        "This section is off by default. It loads `model_ultra.pth` and `sae_model_ultra.pth`, registers a hook on the 512D pooled representation, and shows:\n",
        "\n",
        "- Top active SAE features for a run\n",
        "- A tiny “steer” example by editing one active feature and rerunning beam search\n",
        "\n",
        "To enable: set `DOWNLOAD_ULTRA_SAE = True` in the download cell above, then set `RUN_ULTRA_SAE = True` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUN_ULTRA_SAE = False\n",
        "\n",
        "if RUN_ULTRA_SAE:\n",
        "    import json\n",
        "\n",
        "    from splatnlp.monosemantic_sae.hooks import register_hooks\n",
        "    from splatnlp.monosemantic_sae.models import SparseAutoencoder\n",
        "\n",
        "    ultra = SetCompletionModel(**params)\n",
        "    ultra.load_state_dict(\n",
        "        torch.load(OUT_DIR / \"model_ultra.pth\", map_location=\"cpu\")\n",
        "    )\n",
        "    ultra.to(device)\n",
        "    ultra.eval()\n",
        "\n",
        "    sae_cfg = json.loads((OUT_DIR / \"sae_config_ultra.json\").read_text())\n",
        "    sae = SparseAutoencoder(\n",
        "        input_dim=int(sae_cfg.get(\"input_dim\", 512)),\n",
        "        expansion_factor=float(sae_cfg.get(\"expansion_factor\", 48.0)),\n",
        "        l1_coefficient=float(sae_cfg.get(\"l1_coefficient\", 0.0)),\n",
        "        target_usage=float(sae_cfg.get(\"target_usage\", 0.0)),\n",
        "        usage_coeff=float(sae_cfg.get(\"usage_coeff\", 0.0)),\n",
        "        dead_neuron_threshold=float(sae_cfg.get(\"dead_neuron_threshold\", 1e-6)),\n",
        "        dead_neuron_steps=int(sae_cfg.get(\"dead_neuron_steps\", 12500)),\n",
        "    )\n",
        "    sae.load_state_dict(\n",
        "        torch.load(OUT_DIR / \"sae_model_ultra.pth\", map_location=\"cpu\")\n",
        "    )\n",
        "    sae.to(device)\n",
        "    sae.eval()\n",
        "\n",
        "    hook, handle = register_hooks(ultra, sae_model=sae, bypass=False, no_change=True)\n",
        "\n",
        "    def predict_fn_ultra(current_tokens: list[str], weapon_id: str):\n",
        "        ids = [vocab[t] for t in current_tokens]\n",
        "        x = torch.tensor([ids], device=device)\n",
        "        w = torch.tensor([[weapon_vocab[weapon_id]]], device=device)\n",
        "        mask = x == pad_token_id\n",
        "        with torch.no_grad():\n",
        "            probs = torch.sigmoid(ultra(x, w, key_padding_mask=mask)).squeeze(0)\n",
        "        probs = probs.detach().cpu().tolist()\n",
        "        acts = (\n",
        "            hook.last_h_post.detach().cpu().flatten()\n",
        "            if hook.last_h_post is not None\n",
        "            else None\n",
        "        )\n",
        "        return ({inv_vocab[i]: float(probs[i]) for i in range(vocab_size)}, acts)\n",
        "\n",
        "    builds, traces = reconstruct_build(\n",
        "        predict_fn=predict_fn_ultra,\n",
        "        weapon_id=weapon_id,\n",
        "        initial_context=[NULL],\n",
        "        allocator=Allocator(),\n",
        "        beam_size=5,\n",
        "        max_steps=6,\n",
        "        top_k=1,\n",
        "        record_traces=True,\n",
        "    )\n",
        "\n",
        "    if not builds or not traces:\n",
        "        raise RuntimeError(\"No build/trace produced\")\n",
        "\n",
        "    print(\"Ultra build:\")\n",
        "    print(builds[0].to_dict())\n",
        "\n",
        "    last = traces[0][-1]\n",
        "    acts = last.activations\n",
        "    if acts is None:\n",
        "        raise RuntimeError(\"No SAE activations captured\")\n",
        "\n",
        "    topk = torch.topk(acts, k=10)\n",
        "    print(\"\\nTop active SAE features (id -> value):\")\n",
        "    for i, v in zip(topk.indices.tolist(), topk.values.tolist()):\n",
        "        print(int(i), float(v))\n",
        "\n",
        "    # Simple steer: ablate the most-active feature\n",
        "    steer_feature = int(topk.indices[0].item())\n",
        "    hook.update_neuron(steer_feature, 0.0)\n",
        "\n",
        "    builds2 = reconstruct_build(\n",
        "        predict_fn=predict_fn_ultra,\n",
        "        weapon_id=weapon_id,\n",
        "        initial_context=[NULL],\n",
        "        allocator=Allocator(),\n",
        "        beam_size=5,\n",
        "        max_steps=6,\n",
        "        top_k=1,\n",
        "        record_traces=False,\n",
        "    )\n",
        "\n",
        "    print(\"\\nSteered build (feature\", steer_feature, \"-> 0.0):\")\n",
        "    print(builds2[0].to_dict() if builds2 else None)\n",
        "\n",
        "    handle.remove()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "SplatNLP_colab_demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

