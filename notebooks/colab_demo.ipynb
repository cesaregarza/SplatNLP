{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SplatNLP Colab Demo\n",
        "\n",
        "This notebook downloads pretrained artifacts from DigitalOcean Spaces and runs:\n",
        "\n",
        "- Token-space inference (multi-label set completion)\n",
        "- Constraint-aware beam search to produce a legal build\n",
        "- (Optional) Ultra + SAE hook introspection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_URL = \"https://github.com/cesaregarza/SplatNLP.git\"\n",
        "REPO_DIR = Path(\"/content/SplatNLP\")\n",
        "\n",
        "if not REPO_DIR.exists():\n",
        "    subprocess.run(\n",
        "        [\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, str(REPO_DIR)],\n",
        "        check=True,\n",
        "    )\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "sys.path.insert(0, str(REPO_DIR / \"src\"))\n",
        "print(\"Repo ready:\", REPO_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip -q install requests tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download artifacts (Full model)\n",
        "\n",
        "This grabs `model.pth`, `model_params.json`, `vocab.json`, `weapon_vocab.json`, and `model_info.json`.\n",
        "\n",
        "If you want the Ultra + SAE demo later in this notebook, set `DOWNLOAD_ULTRA_SAE = True`.\n",
        "\n",
        "Optional: if you upload feature labels to the same dataset directory (either `feature_labels_ultra.json` or `consolidated_ultra.json`), the Ultra section will display human-readable names (and optionally notes) for top features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from splatnlp.utils.download_artifacts import (\n",
        "    CORE_ARTIFACTS,\n",
        "    ULTRA_ARTIFACTS,\n",
        "    ULTRA_LABELS_ARTIFACTS,\n",
        "    ULTRA_SAE_ARTIFACTS,\n",
        "    download_artifacts,\n",
        ")\n",
        "\n",
        "BASE_URL = \"https://splat-nlp.nyc3.cdn.digitaloceanspaces.com\"\n",
        "DATASET_DIR = \"dataset_v2\"\n",
        "OUT_DIR = Path(\"saved_models\") / DATASET_DIR\n",
        "\n",
        "DOWNLOAD_ULTRA_SAE = False\n",
        "\n",
        "artifacts = list(CORE_ARTIFACTS)\n",
        "if DOWNLOAD_ULTRA_SAE:\n",
        "    artifacts += (\n",
        "        list(ULTRA_ARTIFACTS)\n",
        "        + list(ULTRA_SAE_ARTIFACTS)\n",
        "        + list(ULTRA_LABELS_ARTIFACTS)\n",
        "    )\n",
        "\n",
        "download_artifacts(\n",
        "    base_url=BASE_URL,\n",
        "    dataset_dir=DATASET_DIR,\n",
        "    out_dir=OUT_DIR,\n",
        "    artifacts=artifacts,\n",
        "    force=False,\n",
        "    timeout_s=180,\n",
        "    quiet=False,\n",
        "    dry_run=False,\n",
        ")\n",
        "\n",
        "print(\"Downloaded to:\", OUT_DIR)\n",
        "for p in sorted(OUT_DIR.iterdir()):\n",
        "    print(\" -\", p.name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load model + run token-space inference\n",
        "\n",
        "This model is **multi-label set completion**: it outputs an independent probability for every token (not an autoregressive next-token LM).\n",
        "\n",
        "Tokenization note:\n",
        "- Standard abilities are represented as cumulative threshold tokens (e.g., 12 AP `run_speed_up` \u2192 `run_speed_up_3`, `_6`, `_12`).\n",
        "- Beam search below runs on capstones (highest tier per ability family), then expands them back to cumulative tokens when calling the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import torch\n",
        "\n",
        "from splatnlp.model.models import SetCompletionModel\n",
        "from splatnlp.serve.tokenize import tokenize_build\n",
        "from splatnlp.utils.constants import (\n",
        "    BUCKET_THRESHOLDS,\n",
        "    MAIN_ONLY_ABILITIES,\n",
        "    NULL,\n",
        "    PAD,\n",
        "    STANDARD_ABILITIES,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "params = json.loads((OUT_DIR / \"model_params.json\").read_text())\n",
        "vocab = json.loads((OUT_DIR / \"vocab.json\").read_text())\n",
        "weapon_vocab = json.loads((OUT_DIR / \"weapon_vocab.json\").read_text())\n",
        "\n",
        "pad_token_id = params.get(\"pad_token_id\", vocab[PAD])\n",
        "inv_vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "model = SetCompletionModel(**params)\n",
        "model.load_state_dict(torch.load(OUT_DIR / \"model.pth\", map_location=\"cpu\"))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "weapon_id = (\n",
        "    \"weapon_id_8000\"\n",
        "    if \"weapon_id_8000\" in weapon_vocab\n",
        "    else next(iter(weapon_vocab))\n",
        ")\n",
        "\n",
        "partial_build = {\n",
        "    \"ink_saver_main\": 6,\n",
        "    \"run_speed_up\": 12,\n",
        "    \"intensify_action\": 12,\n",
        "}\n",
        "\n",
        "def build_to_capstones(build: dict[str, int]) -> list[str]:\n",
        "    capstones: list[str] = []\n",
        "    for ability in MAIN_ONLY_ABILITIES:\n",
        "        if build.get(ability):\n",
        "            capstones.append(ability)\n",
        "\n",
        "    for ability in STANDARD_ABILITIES:\n",
        "        ap = build.get(ability)\n",
        "        if ap is None:\n",
        "            continue\n",
        "        ap = int(ap)\n",
        "        thresh = max((t for t in BUCKET_THRESHOLDS if t <= ap), default=None)\n",
        "        if thresh is None:\n",
        "            continue\n",
        "        capstones.append(f\"{ability}_{thresh}\")\n",
        "\n",
        "    return capstones or [NULL]\n",
        "\n",
        "def predict_probs(context_tokens: list[str]) -> torch.Tensor:\n",
        "    x = torch.tensor([[vocab[t] for t in context_tokens]], device=device)\n",
        "    w = torch.tensor([[weapon_vocab[weapon_id]]], device=device)\n",
        "    mask = x == pad_token_id\n",
        "    with torch.no_grad():\n",
        "        probs = torch.sigmoid(model(x, w, key_padding_mask=mask)).squeeze(0)\n",
        "    return probs.detach().cpu()\n",
        "\n",
        "def predict_top_tokens(context_tokens: list[str], k: int = 15):\n",
        "    probs_cpu = predict_probs(context_tokens)\n",
        "    skip = {vocab.get(PAD), vocab.get(NULL)}\n",
        "    top = torch.topk(probs_cpu, k=min(k, probs_cpu.numel()))\n",
        "    out = []\n",
        "    for idx, p in zip(top.indices.tolist(), top.values.tolist()):\n",
        "        if idx in skip:\n",
        "            continue\n",
        "        out.append((inv_vocab[idx], float(p)))\n",
        "    return out\n",
        "\n",
        "baseline_tokens = [NULL]\n",
        "partial_tokens = tokenize_build(partial_build)\n",
        "capstone_tokens = build_to_capstones(partial_build)\n",
        "\n",
        "print(\"weapon_id:\", weapon_id)\n",
        "print(\"partial_build:\", partial_build)\n",
        "print(\"partial_tokens (cumulative):\", partial_tokens)\n",
        "print(\"capstone_tokens (for beam search):\", capstone_tokens)\n",
        "\n",
        "print(\"\\nTop predictions from <NULL> (baseline):\")\n",
        "for tok, p in predict_top_tokens(baseline_tokens):\n",
        "    print(f\"{tok:<32} {p:.4f}\")\n",
        "\n",
        "print(\"\\nTop predictions from partial build tokens:\")\n",
        "for tok, p in predict_top_tokens(partial_tokens):\n",
        "    print(f\"{tok:<32} {p:.4f}\")\n",
        "\n",
        "baseline_probs = predict_probs(baseline_tokens)\n",
        "partial_probs = predict_probs(partial_tokens)\n",
        "delta = partial_probs - baseline_probs\n",
        "\n",
        "def top_delta_tokens(delta_vec: torch.Tensor, k: int, *, largest: bool):\n",
        "    skip = {vocab.get(PAD), vocab.get(NULL)}\n",
        "    values, indices = torch.topk(\n",
        "        delta_vec if largest else -delta_vec,\n",
        "        k=min(k, delta_vec.numel()),\n",
        "    )\n",
        "    out = []\n",
        "    for idx, v in zip(indices.tolist(), values.tolist()):\n",
        "        if idx in skip:\n",
        "            continue\n",
        "        dv = float(v) if largest else -float(v)\n",
        "        out.append((inv_vocab[idx], dv))\n",
        "    return out\n",
        "\n",
        "print(\"\\nTop +\u0394 tokens (partial - baseline):\")\n",
        "for tok, dv in top_delta_tokens(delta, k=12, largest=True):\n",
        "    print(f\"{tok:<32} {dv:+.4f}\")\n",
        "\n",
        "print(\"\\nTop -\u0394 tokens (partial - baseline):\")\n",
        "for tok, dv in top_delta_tokens(delta, k=12, largest=False):\n",
        "    print(f\"{tok:<32} {dv:+.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Beam search: token-space \u2192 legal build-space\n",
        "\n",
        "We run two demos:\n",
        "\n",
        "- Baseline build from `<NULL>` only\n",
        "- Completion given a partial build (capstone tokens)\n",
        "\n",
        "This uses the repo\u2019s constraint-aware reconstruction (allocator + beam search).\n",
        "\n",
        "Tip: set `SHOW_TRACE = True` to print a compact step-by-step trace.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from splatnlp.utils.reconstruct.allocator import Allocator\n",
        "from splatnlp.utils.reconstruct.beam_search import reconstruct_build\n",
        "\n",
        "import time\n",
        "\n",
        "allocator = Allocator()\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "def predict_fn(current_tokens: list[str], weapon_id: str):\n",
        "    ids = [vocab[t] for t in current_tokens]\n",
        "    x = torch.tensor([ids], device=device)\n",
        "    w = torch.tensor([[weapon_vocab[weapon_id]]], device=device)\n",
        "    mask = x == pad_token_id\n",
        "    with torch.no_grad():\n",
        "        probs = torch.sigmoid(model(x, w, key_padding_mask=mask)).squeeze(0)\n",
        "    probs = probs.detach().cpu().tolist()\n",
        "    return {inv_vocab[i]: float(probs[i]) for i in range(vocab_size)}\n",
        "\n",
        "def summarize_trace(trace, top_preds: int = 8) -> None:\n",
        "    seen = set()\n",
        "    for fr in trace:\n",
        "        caps = sorted(fr.partial_caps.keys())\n",
        "        added = sorted(set(caps) - seen)\n",
        "        seen.update(caps)\n",
        "        top = sorted(fr.logits.items(), key=lambda kv: kv[1], reverse=True)\n",
        "        top = [(t, round(p, 4)) for t, p in top if not t.startswith(\"<\")][:top_preds]\n",
        "        print({\"step\": fr.step, \"added\": added, \"top_preds\": top})\n",
        "\n",
        "def print_build(label: str, build) -> None:\n",
        "    d = build.to_dict()\n",
        "    achieved = dict(\n",
        "        sorted(d[\"achieved_ap\"].items(), key=lambda kv: kv[1], reverse=True)\n",
        "    )\n",
        "    print(f\"\\n{label}\")\n",
        "    print(\"total_ap:\", d[\"total_ap\"])\n",
        "    print(\"mains:\", d[\"mains\"])\n",
        "    print(\"subs:\", d[\"subs\"])\n",
        "    print(\"achieved_ap:\", achieved)\n",
        "\n",
        "SHOW_TRACE = False\n",
        "\n",
        "def run_beam(label: str, initial_context: list[str]):\n",
        "    start = time.perf_counter()\n",
        "    if SHOW_TRACE:\n",
        "        builds, traces = reconstruct_build(\n",
        "            predict_fn=predict_fn,\n",
        "            weapon_id=weapon_id,\n",
        "            initial_context=initial_context,\n",
        "            allocator=allocator,\n",
        "            beam_size=5,\n",
        "            max_steps=6,\n",
        "            top_k=1,\n",
        "            record_traces=True,\n",
        "        )\n",
        "    else:\n",
        "        builds = reconstruct_build(\n",
        "            predict_fn=predict_fn,\n",
        "            weapon_id=weapon_id,\n",
        "            initial_context=initial_context,\n",
        "            allocator=allocator,\n",
        "            beam_size=5,\n",
        "            max_steps=6,\n",
        "            top_k=1,\n",
        "            record_traces=False,\n",
        "        )\n",
        "        traces = None\n",
        "\n",
        "    elapsed = time.perf_counter() - start\n",
        "    print(f\"{label} runtime: {elapsed:.3f}s\")\n",
        "\n",
        "    if not builds:\n",
        "        raise RuntimeError(f\"No valid build produced for: {label}\")\n",
        "\n",
        "    build = builds[0]\n",
        "    print_build(label, build)\n",
        "\n",
        "    if SHOW_TRACE:\n",
        "        summarize_trace(traces[0])\n",
        "\n",
        "    return build\n",
        "\n",
        "baseline_build = run_beam(\"Baseline build (<NULL>)\", [NULL])\n",
        "completion_build = run_beam(\"Completion from partial capstones\", capstone_tokens)\n",
        "\n",
        "def print_ap_delta(a, b, *, max_rows: int = 15) -> None:\n",
        "    a_ap = a.to_dict()[\"achieved_ap\"]\n",
        "    b_ap = b.to_dict()[\"achieved_ap\"]\n",
        "    rows = []\n",
        "    for ability in sorted(set(a_ap) | set(b_ap)):\n",
        "        av = int(a_ap.get(ability, 0))\n",
        "        bv = int(b_ap.get(ability, 0))\n",
        "        if av == bv:\n",
        "            continue\n",
        "        rows.append((ability, av, bv, bv - av))\n",
        "\n",
        "    rows.sort(key=lambda r: abs(r[3]), reverse=True)\n",
        "    print(\"\\nAP changes (completion - baseline):\")\n",
        "    for ability, av, bv, dv in rows[:max_rows]:\n",
        "        print(f\"{ability:<24} {av:>2} -> {bv:>2} ({dv:+d})\")\n",
        "\n",
        "def check_constraints(build, requested: dict[str, int]) -> None:\n",
        "    achieved = build.to_dict()[\"achieved_ap\"]\n",
        "    ok = True\n",
        "    print(\"\\nConstraint check (completion build):\")\n",
        "    for ability, req in requested.items():\n",
        "        got = int(achieved.get(ability, 0))\n",
        "        met = got >= int(req)\n",
        "        ok = ok and met\n",
        "        status = \"OK\" if met else \"FAIL\"\n",
        "        print(f\"{ability:<24} req={req:>2} got={got:>2} {status}\")\n",
        "    print(\"all_met:\", ok)\n",
        "\n",
        "print_ap_delta(baseline_build, completion_build)\n",
        "check_constraints(completion_build, partial_build)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build \u2194 token visualization\n",
        "\n",
        "This renders a 57-AP build as **3 mains + 9 subs**, then shows how it collapses to token-space:\n",
        "\n",
        "- **Beam-search capstones** (highest tier per ability family)\n",
        "- **Cumulative threshold tokens** (what the model actually sees)\n",
        "\n",
        "Sub-slot ordering is not unique; this is just a display assignment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import html as _html\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "from splatnlp.serve.tokenize import tokenize_build\n",
        "from splatnlp.utils.constants import (\n",
        "    BUCKET_THRESHOLDS,\n",
        "    MAIN_ONLY_ABILITIES,\n",
        "    NULL,\n",
        "    STANDARD_ABILITIES,\n",
        ")\n",
        "\n",
        "def _abbrev(token: str) -> str:\n",
        "    special = {\n",
        "        \"ink_recovery_up\": \"iru\",\n",
        "        \"ink_resistance_up\": \"res\",\n",
        "        \"ink_saver_main\": \"ism\",\n",
        "        \"ink_saver_sub\": \"iss\",\n",
        "        \"quick_respawn\": \"qr\",\n",
        "        \"quick_super_jump\": \"qsj\",\n",
        "        \"run_speed_up\": \"rsu\",\n",
        "        \"sub_resistance_up\": \"sru\",\n",
        "        \"special_charge_up\": \"scu\",\n",
        "        \"special_power_up\": \"spu\",\n",
        "        \"special_saver\": \"ss\",\n",
        "        \"sub_power_up\": \"bpu\",\n",
        "        \"swim_speed_up\": \"ssu\",\n",
        "        \"intensify_action\": \"ia\",\n",
        "    }\n",
        "    base = token\n",
        "    suffix = \"\"\n",
        "    if \"_\" in token and token.rsplit(\"_\", 1)[-1].isdigit():\n",
        "        base, suffix = token.rsplit(\"_\", 1)\n",
        "    short = special.get(base) or \"\".join(w[0] for w in base.split(\"_\"))\n",
        "    return f\"{short}{suffix}\" if suffix else short\n",
        "\n",
        "def _ap_to_capstones(ap: dict[str, int]) -> list[str]:\n",
        "    caps: list[str] = []\n",
        "    for ability in MAIN_ONLY_ABILITIES:\n",
        "        if int(ap.get(ability, 0) or 0) > 0:\n",
        "            caps.append(ability)\n",
        "    for ability in STANDARD_ABILITIES:\n",
        "        val = int(ap.get(ability, 0) or 0)\n",
        "        thresh = max(\n",
        "            (t for t in BUCKET_THRESHOLDS if t <= val),\n",
        "            default=None,\n",
        "        )\n",
        "        if thresh is not None:\n",
        "            caps.append(f\"{ability}_{thresh}\")\n",
        "    return caps or [NULL]\n",
        "\n",
        "def _palette(n: int) -> list[str]:\n",
        "    base = [\n",
        "        \"#4c78a8\",\n",
        "        \"#f58518\",\n",
        "        \"#54a24b\",\n",
        "        \"#e45756\",\n",
        "        \"#72b7b2\",\n",
        "        \"#b279a2\",\n",
        "        \"#ff9da6\",\n",
        "        \"#9d755d\",\n",
        "        \"#bab0ac\",\n",
        "        \"#1f77b4\",\n",
        "        \"#ff7f0e\",\n",
        "        \"#2ca02c\",\n",
        "        \"#d62728\",\n",
        "        \"#9467bd\",\n",
        "    ]\n",
        "    if n <= len(base):\n",
        "        return base[:n]\n",
        "    return [base[i % len(base)] for i in range(n)]\n",
        "\n",
        "def _build_color_map(*build_dicts: dict) -> dict[str, str]:\n",
        "    fams: set[str] = set()\n",
        "    for d in build_dicts:\n",
        "        fams.update(d.get(\"achieved_ap\", {}).keys())\n",
        "        for v in d.get(\"mains\", {}).values():\n",
        "            if v is not None:\n",
        "                fams.add(v)\n",
        "        fams.update(d.get(\"subs\", {}).keys())\n",
        "    fam_list = sorted(fams)\n",
        "    cols = _palette(len(fam_list))\n",
        "    return {fam: col for fam, col in zip(fam_list, cols)}\n",
        "\n",
        "def _expand_subs(subs: dict[str, int]) -> list[str | None]:\n",
        "    items = []\n",
        "    for fam, c in sorted(\n",
        "        subs.items(),\n",
        "        key=lambda kv: (-int(kv[1]), kv[0]),\n",
        "    ):\n",
        "        items.extend([fam] * int(c))\n",
        "    if len(items) < 9:\n",
        "        items.extend([None] * (9 - len(items)))\n",
        "    return items[:9]\n",
        "\n",
        "def _render_build_card(title: str, build, *, colors: dict[str, str]) -> str:\n",
        "    d = build.to_dict()\n",
        "    mains = d[\"mains\"]\n",
        "    subs = _expand_subs(d[\"subs\"])\n",
        "    subs_by_slot = {\n",
        "        \"head\": subs[0:3],\n",
        "        \"clothes\": subs[3:6],\n",
        "        \"shoes\": subs[6:9],\n",
        "    }\n",
        "\n",
        "    ap = {k: int(v) for k, v in d[\"achieved_ap\"].items()}\n",
        "    cumulative = tokenize_build(ap)\n",
        "    capstones = _ap_to_capstones(ap)\n",
        "\n",
        "    def slot_box(label: str | None, kind: str) -> str:\n",
        "        if label is None:\n",
        "            return f\"<div class='slot {kind} empty'>empty</div>\"\n",
        "        col = colors.get(label, \"#eee\")\n",
        "        txt = _html.escape(_abbrev(label))\n",
        "        full = _html.escape(label)\n",
        "        return (\n",
        "            f\"<div class='slot {kind}' title='{full}' \"\n",
        "            f\"style='background:{col}22;border-color:{col}55'>\"\n",
        "            f\"<span class='slot-txt'>{txt}</span>\"\n",
        "            \"</div>\"\n",
        "        )\n",
        "\n",
        "    gear_cols = []\n",
        "    for slot_name in [\"head\", \"clothes\", \"shoes\"]:\n",
        "        main = mains.get(slot_name)\n",
        "        col_html = [\n",
        "            \"<div class='gear-col'>\",\n",
        "            f\"<div class='gear-title'>{slot_name.title()}</div>\",\n",
        "            slot_box(main, \"main\"),\n",
        "        ]\n",
        "        for sub in subs_by_slot[slot_name]:\n",
        "            col_html.append(slot_box(sub, \"sub\"))\n",
        "        col_html.append(\"</div>\")\n",
        "        gear_cols.append(\"\\n\".join(col_html))\n",
        "\n",
        "    main_counts = Counter([m for m in mains.values() if m is not None])\n",
        "    rows = []\n",
        "    for fam in sorted(ap.keys()):\n",
        "        ap_val = int(ap[fam])\n",
        "        m = int(main_counts.get(fam, 0))\n",
        "        s = int(d[\"subs\"].get(fam, 0))\n",
        "        col = colors.get(fam, \"#eee\")\n",
        "\n",
        "        toks = []\n",
        "        cap = None\n",
        "        if fam in MAIN_ONLY_ABILITIES:\n",
        "            toks = [fam]\n",
        "            cap = fam\n",
        "        elif fam in STANDARD_ABILITIES:\n",
        "            toks = [f\"{fam}_{t}\" for t in BUCKET_THRESHOLDS if t <= ap_val]\n",
        "            cap = toks[-1] if toks else None\n",
        "\n",
        "        chip_html = []\n",
        "        for t in toks:\n",
        "            short = _html.escape(_abbrev(t))\n",
        "            full = _html.escape(t)\n",
        "            cls = \"chip cap\" if t == cap else \"chip\"\n",
        "            chip_html.append(\n",
        "                f\"<span class='{cls}' title='{full}' \"\n",
        "                f\"style='border-color:{col}88'>{short}</span>\"\n",
        "            )\n",
        "\n",
        "        rows.append(\n",
        "            \"\\n\".join(\n",
        "                [\n",
        "                    \"<tr>\",\n",
        "                    (\n",
        "                        \"<td>\"\n",
        "                        f\"<span class='fam' title='{_html.escape(fam)}' \"\n",
        "                        f\"style='background:{col}22;border-color:{col}55'>\"\n",
        "                        f\"{_html.escape(_abbrev(fam))}</span>\"\n",
        "                        \"</td>\"\n",
        "                    ),\n",
        "                    f\"<td>{m}</td>\",\n",
        "                    f\"<td>{s}</td>\",\n",
        "                    f\"<td>{ap_val}</td>\",\n",
        "                    f\"<td>{''.join(chip_html) if chip_html else ''}</td>\",\n",
        "                    \"</tr>\",\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def list_as_code(items: list[str]) -> str:\n",
        "        safe = \", \".join(_html.escape(x) for x in items)\n",
        "        return f\"<code>{safe}</code>\"\n",
        "\n",
        "    cap_n = len([t for t in capstones if t != NULL])\n",
        "    cum_n = len([t for t in cumulative if t != NULL])\n",
        "    return \"\\n\".join(\n",
        "        [\n",
        "            \"<div class='flow-card'>\",\n",
        "            f\"<div class='flow-title'>{_html.escape(title)}</div>\",\n",
        "            (\n",
        "                f\"<div class='small'>total_ap={int(d['total_ap'])} | \"\n",
        "                f\"capstones={cap_n} | cumulative_tokens={cum_n}</div>\"\n",
        "            ),\n",
        "            \"<div class='gear-grid'>\",\n",
        "            *gear_cols,\n",
        "            \"</div>\",\n",
        "            \"<details class='details'><summary>Beam-search capstones</summary>\",\n",
        "            list_as_code(capstones),\n",
        "            \"</details>\",\n",
        "            \"<details class='details'><summary>Tokens fed to model (cumulative)</summary>\",\n",
        "            list_as_code(cumulative),\n",
        "            \"</details>\",\n",
        "            \"<div class='small' style='margin-top:8px'>\",\n",
        "            \"Per-family breakdown (capstone token is bold):\",\n",
        "            \"</div>\",\n",
        "            \"<table class='tbl'>\",\n",
        "            \"<thead><tr><th>fam</th><th>m</th><th>s</th><th>AP</th><th>tokens</th></tr></thead>\",\n",
        "            \"<tbody>\",\n",
        "            *rows,\n",
        "            \"</tbody></table>\",\n",
        "            \"<div class='small note'>\",\n",
        "            \"Note: sub-slot order is not unique; this is a display assignment.\",\n",
        "            \"</div>\",\n",
        "            \"</div>\",\n",
        "        ]\n",
        "    )\n",
        "\n",
        "STYLE = \"\"\"\n",
        "<style>\n",
        ".flow-wrap{font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Arial;}\n",
        ".flow-row{display:flex;gap:14px;flex-wrap:wrap;align-items:flex-start;}\n",
        ".flow-card{border:1px solid #e6e6e6;border-radius:14px;padding:12px;width:520px;box-shadow:0 1px 0 rgba(0,0,0,0.02);}\n",
        ".flow-title{font-weight:700;font-size:14px;margin-bottom:2px;}\n",
        ".small{color:#555;font-size:12px;}\n",
        ".gear-grid{display:grid;grid-template-columns:repeat(3,1fr);gap:10px;margin-top:10px;}\n",
        ".gear-col{background:#fafafa;border:1px solid #eee;border-radius:12px;padding:8px;}\n",
        ".gear-title{font-weight:600;font-size:12px;color:#333;margin-bottom:6px;}\n",
        ".slot{border-radius:10px;padding:6px 8px;margin-top:6px;border:1px solid rgba(0,0,0,0.08);font-size:12px;}\n",
        ".slot.main{font-weight:700;}\n",
        ".slot.sub{font-weight:600;}\n",
        ".slot.empty{background:#f0f0f0;color:#888;border-color:#e0e0e0;}\n",
        ".slot-txt{display:inline-block;letter-spacing:0.2px;}\n",
        ".details{margin-top:10px;}\n",
        ".details summary{cursor:pointer;color:#333;font-size:12px;font-weight:600;}\n",
        "code{background:#f6f6f6;border:1px solid #eee;padding:2px 6px;border-radius:8px;font-size:11px;}\n",
        ".tbl{width:100%;border-collapse:collapse;margin-top:6px;}\n",
        ".tbl th,.tbl td{border-bottom:1px solid #eee;padding:4px 6px;font-size:11px;vertical-align:top;}\n",
        ".tbl th{color:#333;text-align:left;font-weight:700;}\n",
        ".fam{display:inline-block;padding:2px 8px;border-radius:999px;border:1px solid rgba(0,0,0,0.12);font-weight:700;font-size:11px;}\n",
        ".chip{display:inline-block;margin:2px 4px 2px 0;padding:2px 8px;border-radius:999px;border:1px solid rgba(0,0,0,0.12);background:#fff;font-size:11px;}\n",
        ".chip.cap{border-width:2px;font-weight:800;}\n",
        ".note{margin-top:8px;}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "baseline_d = baseline_build.to_dict()\n",
        "completion_d = completion_build.to_dict()\n",
        "color_map = _build_color_map(baseline_d, completion_d)\n",
        "\n",
        "html_out = \"\\n\".join(\n",
        "    [\n",
        "        \"<div class='flow-wrap'>\",\n",
        "        STYLE,\n",
        "        \"<div class='flow-row'>\",\n",
        "        _render_build_card(\"Baseline build\", baseline_build, colors=color_map),\n",
        "        _render_build_card(\"Completion build\", completion_build, colors=color_map),\n",
        "        \"</div>\",\n",
        "        \"</div>\",\n",
        "    ]\n",
        ")\n",
        "display(HTML(html_out))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Ultra + SAE hook introspection\n",
        "\n",
        "This section is off by default. It loads `model_ultra.pth` and `sae_model_ultra.pth`, registers a hook on the 512D pooled representation, and shows:\n",
        "\n",
        "- Hook fidelity stats (bypass vs SAE reconstruction)\n",
        "- Top active SAE features for a run\n",
        "- Top tokens most influenced by a feature\n",
        "- (If available) human labels for features\n",
        "\n",
        "Note: `no_change=True` captures SAE activations without changing model outputs; `no_change=False` inserts the SAE reconstruction (used in the fidelity check).\n",
        "\n",
        "If you have label notes available, set `SHOW_LABEL_NOTES = True` in the code cell.\n",
        "\n",
        "To enable: set `DOWNLOAD_ULTRA_SAE = True` in the download cell above, then set `RUN_ULTRA_SAE = True` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUN_ULTRA_SAE = False\n",
        "\n",
        "if RUN_ULTRA_SAE:\n",
        "    import json\n",
        "\n",
        "    import torch\n",
        "\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    from splatnlp.monosemantic_sae.hooks import register_hooks\n",
        "    from splatnlp.monosemantic_sae.models import SparseAutoencoder\n",
        "    from splatnlp.utils.reconstruct.allocator import Allocator\n",
        "    from splatnlp.utils.reconstruct.beam_search import reconstruct_build\n",
        "\n",
        "    ultra = SetCompletionModel(**params)\n",
        "    ultra.load_state_dict(\n",
        "        torch.load(OUT_DIR / \"model_ultra.pth\", map_location=\"cpu\")\n",
        "    )\n",
        "    ultra.to(device)\n",
        "    ultra.eval()\n",
        "\n",
        "    sae_cfg = json.loads((OUT_DIR / \"sae_config_ultra.json\").read_text())\n",
        "    sae = SparseAutoencoder(\n",
        "        input_dim=int(sae_cfg.get(\"input_dim\", 512)),\n",
        "        expansion_factor=float(sae_cfg.get(\"expansion_factor\", 48.0)),\n",
        "        l1_coefficient=float(sae_cfg.get(\"l1_coefficient\", 0.0)),\n",
        "        target_usage=float(sae_cfg.get(\"target_usage\", 0.0)),\n",
        "        usage_coeff=float(sae_cfg.get(\"usage_coeff\", 0.0)),\n",
        "        dead_neuron_threshold=float(sae_cfg.get(\"dead_neuron_threshold\", 1e-6)),\n",
        "        dead_neuron_steps=int(sae_cfg.get(\"dead_neuron_steps\", 12500)),\n",
        "    )\n",
        "    sae.load_state_dict(\n",
        "        torch.load(OUT_DIR / \"sae_model_ultra.pth\", map_location=\"cpu\")\n",
        "    )\n",
        "    sae.to(device)\n",
        "    sae.eval()\n",
        "\n",
        "    hook, handle = register_hooks(\n",
        "        ultra,\n",
        "        sae_model=sae,\n",
        "        bypass=False,\n",
        "        no_change=True,\n",
        "    )\n",
        "\n",
        "    vocab_size = len(vocab)\n",
        "\n",
        "    SHOW_LABEL_NOTES = False\n",
        "    MAX_NOTE_CHARS = 220\n",
        "\n",
        "    def _compress_ws(text: str) -> str:\n",
        "        return \" \".join((text or \"\").strip().split())\n",
        "\n",
        "    def load_ultra_feature_labels() -> dict[int, dict[str, str]]:\n",
        "        candidates = [\n",
        "            OUT_DIR / \"consolidated_ultra.json\",\n",
        "            OUT_DIR / \"feature_labels_ultra.json\",\n",
        "        ]\n",
        "        for path in candidates:\n",
        "            if not path.exists():\n",
        "                continue\n",
        "\n",
        "            raw = json.loads(path.read_text())\n",
        "            if not isinstance(raw, dict):\n",
        "                continue\n",
        "\n",
        "            # Consolidated schema (feature_id/display_name/dashboard_notes/...)\n",
        "            consolidated = any(\n",
        "                isinstance(v, dict)\n",
        "                and (\n",
        "                    \"feature_id\" in v\n",
        "                    or \"display_name\" in v\n",
        "                    or \"dashboard_name\" in v\n",
        "                    or \"dashboard_notes\" in v\n",
        "                )\n",
        "                for v in raw.values()\n",
        "            )\n",
        "\n",
        "            labels: dict[int, dict[str, str]] = {}\n",
        "            if consolidated:\n",
        "                for k, v in raw.items():\n",
        "                    if not isinstance(v, dict):\n",
        "                        continue\n",
        "                    fid = v.get(\"feature_id\")\n",
        "                    if fid is None:\n",
        "                        try:\n",
        "                            fid = int(k)\n",
        "                        except (TypeError, ValueError):\n",
        "                            continue\n",
        "                    labels[int(fid)] = {\n",
        "                        \"name\": v.get(\"display_name\")\n",
        "                        or v.get(\"dashboard_name\")\n",
        "                        or \"\",\n",
        "                        \"category\": v.get(\"dashboard_category\") or \"none\",\n",
        "                        \"notes\": v.get(\"dashboard_notes\") or \"\",\n",
        "                    }\n",
        "                return labels\n",
        "\n",
        "            # Dashboard schema (FeatureLabel: name/category/notes/timestamp)\n",
        "            for k, v in raw.items():\n",
        "                if not isinstance(v, dict):\n",
        "                    continue\n",
        "                try:\n",
        "                    fid = int(k)\n",
        "                except ValueError:\n",
        "                    continue\n",
        "                labels[fid] = {\n",
        "                    \"name\": v.get(\"name\") or \"\",\n",
        "                    \"category\": v.get(\"category\") or \"none\",\n",
        "                    \"notes\": v.get(\"notes\") or \"\",\n",
        "                }\n",
        "            return labels\n",
        "\n",
        "        return {}\n",
        "\n",
        "    feature_labels = load_ultra_feature_labels()\n",
        "    if feature_labels:\n",
        "        print(\"Loaded feature labels:\", len(feature_labels))\n",
        "\n",
        "    def forward_probs(tokens: list[str], weapon_id: str) -> torch.Tensor:\n",
        "        ids = [vocab[t] for t in tokens]\n",
        "        x = torch.tensor([ids], device=device)\n",
        "        w = torch.tensor([[weapon_vocab[weapon_id]]], device=device)\n",
        "        mask = x == pad_token_id\n",
        "        with torch.no_grad():\n",
        "            probs = torch.sigmoid(ultra(x, w, key_padding_mask=mask)).squeeze(0)\n",
        "        return probs.detach().cpu()\n",
        "\n",
        "    def predict_fn_ultra(current_tokens: list[str], weapon_id: str):\n",
        "        probs = forward_probs(current_tokens, weapon_id).tolist()\n",
        "        acts = (\n",
        "            hook.last_h_post.detach().cpu().flatten()\n",
        "            if hook.last_h_post is not None\n",
        "            else None\n",
        "        )\n",
        "        return ({inv_vocab[i]: float(probs[i]) for i in range(vocab_size)}, acts)\n",
        "\n",
        "    # Hook fidelity: compare bypassed outputs vs SAE reconstruction.\n",
        "    context = [NULL]\n",
        "    hook.set_mode(bypass=True)\n",
        "    p_bypass = forward_probs(context, weapon_id)\n",
        "\n",
        "    hook.set_mode(bypass=False, no_change=False)\n",
        "    p_recon = forward_probs(context, weapon_id)\n",
        "    p_delta = p_recon - p_bypass\n",
        "\n",
        "    print(\"Hook fidelity (bypass vs recon):\")\n",
        "    print(\"prob max |Δ|:\", float(p_delta.abs().max()))\n",
        "    print(\"prob mean |Δ|:\", float(p_delta.abs().mean()))\n",
        "    if hook.last_in is not None and hook.last_x_recon is not None:\n",
        "        x = hook.last_in.detach().cpu().flatten()\n",
        "        x_recon = hook.last_x_recon.detach().cpu().flatten()\n",
        "        print(\"x recon MSE:\", float(F.mse_loss(x_recon, x)))\n",
        "        print(\"x recon cosine:\", float(F.cosine_similarity(x_recon, x, dim=0)))\n",
        "\n",
        "    # Run a traced beam search so we can see activations.\n",
        "    hook.set_mode(bypass=False, no_change=True)\n",
        "    builds, traces = reconstruct_build(\n",
        "        predict_fn=predict_fn_ultra,\n",
        "        weapon_id=weapon_id,\n",
        "        initial_context=[NULL],\n",
        "        allocator=Allocator(),\n",
        "        beam_size=5,\n",
        "        max_steps=6,\n",
        "        top_k=1,\n",
        "        record_traces=True,\n",
        "    )\n",
        "\n",
        "    if not builds or not traces:\n",
        "        raise RuntimeError(\"No build/trace produced\")\n",
        "\n",
        "    print(\"\\nUltra build:\")\n",
        "    print(builds[0].to_dict())\n",
        "\n",
        "    acts = traces[0][-1].activations\n",
        "    if acts is None:\n",
        "        raise RuntimeError(\"No SAE activations captured\")\n",
        "\n",
        "    topk = torch.topk(acts, k=10)\n",
        "    print(\"\\nTop active SAE features:\")\n",
        "    for i, v in zip(topk.indices.tolist(), topk.values.tolist()):\n",
        "        fid = int(i)\n",
        "        val = float(v)\n",
        "        meta = feature_labels.get(fid)\n",
        "        if not meta:\n",
        "            print(fid, val)\n",
        "            continue\n",
        "        cat = meta.get(\"category\", \"none\")\n",
        "        name = (meta.get(\"name\") or \"\").strip()\n",
        "        if name:\n",
        "            print(f\"{fid:5d} {val:.4f} [{cat}] {name}\")\n",
        "        else:\n",
        "            print(f\"{fid:5d} {val:.4f} [{cat}]\")\n",
        "        if SHOW_LABEL_NOTES:\n",
        "            notes = _compress_ws(meta.get(\"notes\", \"\"))\n",
        "            if notes:\n",
        "                if len(notes) > MAX_NOTE_CHARS:\n",
        "                    notes = notes[: MAX_NOTE_CHARS - 1] + \"\u2026\"\n",
        "                print(\"      notes:\", notes)\n",
        "\n",
        "    # Pick one feature and show what it most influences.\n",
        "    feature_id = int(topk.indices[0].item())\n",
        "    feature_value = float(acts[feature_id])\n",
        "    print(f\"\\nExample feature: {feature_id} (value={feature_value:.4f})\")\n",
        "    if feature_labels.get(feature_id):\n",
        "        meta = feature_labels[feature_id]\n",
        "        name = (meta.get(\"name\") or \"\").strip()\n",
        "        cat = meta.get(\"category\", \"none\")\n",
        "        if name:\n",
        "            print(f\"label: [{cat}] {name}\")\n",
        "        if SHOW_LABEL_NOTES:\n",
        "            notes = _compress_ws(meta.get(\"notes\", \"\"))\n",
        "            if notes:\n",
        "                if len(notes) > MAX_NOTE_CHARS:\n",
        "                    notes = notes[: MAX_NOTE_CHARS - 1] + \"\u2026\"\n",
        "                print(\"notes:\", notes)\n",
        "\n",
        "    decoder_norm = F.normalize(sae.decoder.weight, dim=0)\n",
        "    influence = ultra.output_layer.weight @ decoder_norm[:, feature_id]\n",
        "    influence = influence.detach().cpu().tolist()\n",
        "\n",
        "    infl_pairs = []\n",
        "    for i, val in enumerate(influence):\n",
        "        tok = inv_vocab[i]\n",
        "        if tok.startswith(\"<\"):\n",
        "            continue\n",
        "        infl_pairs.append((tok, float(val)))\n",
        "    infl_pairs.sort(key=lambda kv: kv[1], reverse=True)\n",
        "\n",
        "    print(\"Top tokens by logit influence for this feature:\")\n",
        "    for tok, val in infl_pairs[:10]:\n",
        "        print(f\"{tok:<32} {val:+.4f}\")\n",
        "\n",
        "    handle.remove()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "SplatNLP_colab_demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
